{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# set gpu number to 2\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from attention_all_layers import TemporalAugmentedDataset, EvalDataWrapper\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "from utils.transforms import MeanFlat, RandomRepeatedNoise, Identity\n",
    "from functools import partial\n",
    "\n",
    "eye = Identity()\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    os.sched_setaffinity(0, range(os.cpu_count()))\n",
    "\n",
    "\n",
    "timestep_transforms = [eye] * 20\n",
    "# Create instances of the Fashion MNIST dataset\n",
    "test_dataset = TemporalAugmentedDataset('test', transform=transform,\n",
    "                                img_to_timesteps_transforms=timestep_transforms)\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from utils.visualization import visualize_first_batch_with_timesteps\n",
    "\n",
    "test_loader = DataLoader(EvalDataWrapper(test_dataset, contrast=1, rep_noise=False), batch_size=100, shuffle=False, num_workers=30, worker_init_fn=worker_init_fn)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9429a4c1000739b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from modules.exponential_decay import ExponentialDecay\n",
    "from modules.divisive_norm import DivisiveNorm\n",
    "from modules.div_norm_channel import DivisiveNormChannel\n",
    "from models.HookedRecursiveCNN import HookedRecursiveCNN\n",
    "\n",
    "# HookedRecursiveCNN needs layer_kwargs and div_norm_kwargs to know how to setup the model but the concrete init values are unimportant as they will get overwritten with the pretrained values\n",
    "layer_kwargs = [{'in_channels': 1, 'out_channels': 32, 'kernel_size': 5},\n",
    " {'in_channels': 32, 'out_channels': 32, 'kernel_size': 5},\n",
    " {'in_channels': 32, 'out_channels': 32, 'kernel_size': 3},\n",
    " {'in_channels': 32, 'out_channels': 32, 'kernel_size': 3},\n",
    " {'in_features': 128, 'out_features': 1024}]\n",
    "\n",
    "div_norm_kwargs = [\n",
    "    {\"epsilon\":  1e-8, \"K_init\":  0.2, \"train_K\":  True, \"alpha_init\":  -2.0, \"train_alpha\": True, \"sigma_init\": 0.1, \"train_sigma\": True, 'sqrt': True},\n",
    "    {\"epsilon\":  1e-8, \"K_init\":  1.0, \"train_K\":  False, \"alpha_init\":  -2000000.0, \"train_alpha\": False, \"sigma_init\": 1.0, \"train_sigma\": False, 'sqrt': True},\n",
    "    {\"epsilon\":  1e-8, \"K_init\":  1.0, \"train_K\":  False, \"alpha_init\":  -2000000.0, \"train_alpha\": False, \"sigma_init\": 1.0, \"train_sigma\": False, 'sqrt': True},\n",
    "    {\"epsilon\":  1e-8, \"K_init\":  1.0, \"train_K\":  False, \"alpha_init\":  -2000000.0, \"train_alpha\": False, \"sigma_init\": 1.0, \"train_sigma\": False},\n",
    "    {\"epsilon\":  1e-8, \"K_init\":  1.0, \"train_K\":  False, \"alpha_init\":  0.0, \"train_alpha\": False, \"sigma_init\": 1.0, \"train_sigma\": False}\n",
    "  ]\n",
    "exp_decay_kwargs = [\n",
    "    {\"alpha_init\":  1.0, \"train_alpha\": True, \"beta_init\": 1, \"train_beta\": True},\n",
    "    {\"alpha_init\":  1.0, \"train_alpha\": True, \"beta_init\": 1, \"train_beta\": True},\n",
    "    {\"alpha_init\":  1.0, \"train_alpha\": True, \"beta_init\": 1, \"train_beta\": True},\n",
    "    {\"alpha_init\":  1.0, \"train_alpha\": False, \"beta_init\": 1, \"train_beta\": False},\n",
    "    {\"alpha_init\":  1.0, \"train_alpha\": False, \"beta_init\": 1, \"train_beta\": False}\n",
    "  ]\n",
    "\n",
    "div_norm_cfg = {\n",
    "    't_steps': 20, 'layer_kwargs': layer_kwargs,\n",
    "    'adaptation_module': DivisiveNorm,\n",
    "    'adaptation_kwargs': div_norm_kwargs, 'decode_every_timestep': True\n",
    "}\n",
    "exp_decay_cfg = {\n",
    "    't_steps': 20, 'layer_kwargs': layer_kwargs,\n",
    "    'adaptation_module': ExponentialDecay,\n",
    "    'adaptation_kwargs': exp_decay_kwargs, 'decode_every_timestep': True\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "422830dd443287be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torchmetrics.functional import accuracy\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from temporal_datasets.one_image_temporal_augmented_dataset import OneImageTemporalAugmentedDataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85578bd79d9d4f60"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from utils.transforms import Identity\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.visualization import visualize_first_batch_with_timesteps\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "eye = Identity()\n",
    "\n",
    "timestep_transforms = [eye] * 20\n",
    "split = 'test'\n",
    "batch_size = 50\n",
    "num_workers = 20\n",
    "one_image_dataset = TemporalAugmentedDataset(split, transform=transform,\n",
    "                                img_to_timesteps_transforms=timestep_transforms)\n",
    "\n",
    "shuffle = True if split=='train' else False\n",
    "loader = DataLoader(one_image_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, worker_init_fn=worker_init_fn)\n",
    "\n",
    "x, y = next(iter(loader))\n",
    "int_to_label = {\n",
    "    0: 'T-shirt',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b398fcfa3d3c5597"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrow\n",
    "\n",
    "idx = 7\n",
    "sample = x[idx].permute((0, 2, 3, 1))\n",
    "fig, axes = plt.subplots(1, 20, figsize=(20, 4))  # Adjusted figsize to make it wider\n",
    "fig.subplots_adjust(wspace=0.02)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(sample[i], cmap='gray', vmin=0, vmax=1)  # Set colormap to greyscale\n",
    "    ax.set_xlabel(int_to_label[int(y[idx, i])], rotation=25, labelpad=10, fontsize=14)  # Rotate and position labels\n",
    "    ax.set_xticks([])  # Remove x ticks\n",
    "    ax.set_yticks([])  # Remove y ticks\n",
    "\n",
    "# Drawing a long arrow\n",
    "arrow = FancyArrow(0.15, 0.2, 0.65, 0, width=0.01, color='black', transform=fig.transFigure, clip_on=False)\n",
    "fig.add_artist(arrow)\n",
    "\n",
    "plt.savefig(\"figures/attnl_001.svg\", format='svg')\n",
    "plt.savefig(\"figures/attnl_001.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d45bb40713e706bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torchmetrics.functional import accuracy\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "df = pd.DataFrame({'Model': [], 'Accuracy': [], 'Timestep': []})\n",
    "\n",
    "j=0\n",
    "for x, y in tqdm(loader):\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    for name, model in models.items():\n",
    "        model.cpu()\n",
    "\n",
    "        model.cuda()\n",
    "        \n",
    "        logits = model(x)\n",
    "        for i in range(20):\n",
    "            l = logits[:, i, :]\n",
    "            t = y[:, i]\n",
    "            preds = torch.argmax(l, dim=1)\n",
    "            acc = accuracy(preds, t, task='multiclass', num_classes=10)\n",
    "            df.loc[len(df)] = [name, float(acc.cpu()), i]\n",
    "    j += 1\n",
    "    if j > 50:\n",
    "        break\n",
    "df['Timestep'] += 1\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.set_style('white')\n",
    "sns.lineplot(data=df, x='Timestep', y='Accuracy', hue='Model', palette='dark')\n",
    "plt.ylim(0, 1)\n",
    "sns.despine(offset=10)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"figures/attnl_002.svg\", format='svg')\n",
    "plt.savefig(\"figures/attnl_002.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53dae5ebbb830eda"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x, y = next(iter(loader))\n",
    "x = x.cuda()\n",
    "y = y.cuda()\n",
    "_, cache = div_norm_model.run_with_cache(x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74967c301e15c787"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx = 0\n",
    "map = [0, 7, 0]\n",
    "sample = x[idx].permute((0, 2, 3, 1)).cpu()\n",
    "fig, axes = plt.subplots(ncols=8, nrows=4, figsize=(10, 5))\n",
    "fig.subplots_adjust(wspace=0.03, hspace=0.01)\n",
    "\n",
    "for i, ax in enumerate(axes[0]):\n",
    "    ax.imshow(sample[i], cmap='gray')  # Set colormap to greyscale\n",
    "    ax.set_xticks([]) \n",
    "    ax.set_yticks([]) \n",
    "\n",
    "for layer in range(3):\n",
    "    for i, ax in enumerate(axes[layer+1]):\n",
    "        ax.imshow(cache[f'hks.adapt_{layer}_{i}'][idx, map[layer]].cpu(), vmin=0, vmax=1)\n",
    "        ax.set_xticks([]) \n",
    "        ax.set_yticks([])\n",
    "    axes[layer + 1, 0].set_ylabel(f'Layer {layer + 1}', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Input', fontsize=14)\n",
    "\n",
    "    \n",
    "# Drawing a long arrow\n",
    "arrow = FancyArrow(0.15, 0.05, 0.65, 0, width=0.01, color='black', transform=fig.transFigure, clip_on=False)\n",
    "fig.add_artist(arrow)\n",
    "\n",
    "plt.savefig(\"figures/attnl_005.svg\", format='svg')\n",
    "plt.savefig(\"figures/attnl_005.png\", format='svg')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52ea761cf3da4d21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_loader(split='train', num_workers=10, batch_size=64):\n",
    "    import torchvision.transforms as transforms\n",
    "    from utils.transforms import Identity\n",
    "    from torch.utils.data import DataLoader\n",
    "    from utils.visualization import visualize_first_batch_with_timesteps\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    eye = Identity()\n",
    "\n",
    "    timestep_transforms = [eye] * 20\n",
    "    one_image_dataset = OneImageTemporalAugmentedDataset(split, transform=transform,\n",
    "                                    img_to_timesteps_transforms=timestep_transforms)\n",
    "\n",
    "    shuffle = True if split=='train' else False\n",
    "    loader = DataLoader(one_image_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, worker_init_fn=worker_init_fn)\n",
    "\n",
    "    # visualize_first_batch_with_timesteps(loader, 8)\n",
    "    return loader\n",
    "\n",
    "actv_dict = {'Timestep': [], 'Layer': [], 'Mean': [], 'num_active': [], 'mean_not_null': [], 'Norm': [], 'Model': [], 'State': [], 'Map': []}\n",
    "one_image_dataset = OneImageTemporalAugmentedDataset('test', transform=transform,\n",
    "                                img_to_timesteps_transforms=timestep_transforms)\n",
    "\n",
    "loader = DataLoader(one_image_dataset, batch_size=50, shuffle=False, num_workers=25, pin_memory=True, pin_memory_device='cuda', worker_init_fn=worker_init_fn, persistent_workers=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "273e15df93229aa2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torchmetrics.functional import accuracy\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Model': [], 'Accuracy': [], 'Timestep': []})\n",
    "\n",
    "j=0\n",
    "for x, y in tqdm(loader):\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    for name, model in models.items():\n",
    "        model.cpu()\n",
    "\n",
    "        model.cuda()\n",
    "        \n",
    "        logits = model(x)\n",
    "        for i in range(20):\n",
    "            l = logits[:, i, :]\n",
    "            t = y[:, i]\n",
    "            preds = torch.argmax(l, dim=1)\n",
    "            acc = accuracy(preds, t, task='multiclass', num_classes=10)\n",
    "            df.loc[len(df)] = [name, float(acc.cpu()), i]\n",
    "    j += 1\n",
    "    if j > 50:\n",
    "        break\n",
    "df['Timestep'] += 1\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.set_style('white')\n",
    "sns.lineplot(data=df, x='Timestep', y='Accuracy', hue='Model', palette='dark', legend=False)\n",
    "plt.ylim(0, 1)\n",
    "sns.despine(offset=10)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"figures/attnl_003.svg\", format='svg')\n",
    "plt.savefig(\"figures/attnl_003.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b3dd0826d1b02ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for arg in div_norm_kwargs:\n",
    "    arg['n_channels'] = 32\n",
    "div_norm_channel_cfg = {\n",
    "    't_steps': 20, 'layer_kwargs': layer_kwargs,\n",
    "    'adaptation_module': DivisiveNormChannel,\n",
    "    'adaptation_kwargs': div_norm_kwargs, 'decode_every_timestep': True\n",
    "}\n",
    "div_norm_model = HookedRecursiveCNN.load_from_checkpoint(\n",
    "    'learned_models/new_augmented_attn_all_layers_DivisiveNormChannel_baseline=False_contrast_random_epoch_50.ckpt', div_norm_channel_cfg)\n",
    "models['Divisive Norm. Channel'] = div_norm_model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf3988345530bf2f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "j = 0\n",
    "for x, y in tqdm(loader):\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    for name, model in models.items():\n",
    "        model.cuda()\n",
    "        logits, cache = model.run_with_cache(x)\n",
    "        for layer in range(4):\n",
    "            for timestep in range(20):\n",
    "                actv = cache[f'hks.adapt_{layer}_{timestep}']\n",
    "                for map in range(32):\n",
    "                    actv_dict['Map'].append(map)\n",
    "                    actv_dict['Timestep'].append(timestep)\n",
    "                    actv_dict['Layer'].append(layer)\n",
    "                    actv_dict['Mean'].append(float(actv[:, map].mean()))\n",
    "                    actv_dict['num_active'].append(float((actv[:, map] > 1e-4).sum()))\n",
    "                    actv_dict['mean_not_null'].append(float(actv[:, map][actv[:, map] > 1e-4].mean()))   \n",
    "                    actv_dict['Norm'].append(float(actv[:, map].norm()))\n",
    "                    actv_dict['Model'].append(name)\n",
    "                    actv_dict['State'].append(float(cache[f'hks.state_{layer}_{timestep}'][:, map].mean()))\n",
    "    j += 1\n",
    "    if j > 50:\n",
    "        break\n",
    "\n",
    "actv_df = pd.DataFrame(actv_dict)\n",
    "actv_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4337c221aa1fe19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "actv_df = pd.DataFrame(actv_dict)\n",
    "actv_df['Timestep'] += 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5020a6a95aa2087"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "actv_df['Normalized Activations'] = actv_df.groupby(['Model', 'Layer'], sort=False).apply(lambda df: df['Mean'] / df.loc[df.Timestep==1, 'Mean'].mean()).reset_index(level=['Model', 'Layer'], drop=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9e81e803e2f5683"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.relplot(data=actv_df[actv_df.Model.isin(['Divisive Norm.', 'Additive']) & (actv_df.Layer < 3)], x='Timestep', y='Normalized Activations', hue='Layer', col='Model', kind='line', height=3)\n",
    "sns.despine(offset=5)\n",
    "plt.savefig(\"figures/attnl_004.svg\", format='svg')\n",
    "plt.savefig(\"figures/attnl_004.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67614085cc1002cf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Causal experiments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef6aa533a2c50903"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def hook_fn( actv, hook, target_actv):\n",
    "    return target_actv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8701cb468d0a8660"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "actv_dict = {'Timestep': [], 'Layer': [], 'Mean': [], 'num_active': [], 'mean_not_null': [], 'Norm': [], 'Model': [], 'State': [], 'Map': [], 'Intervention Layer': []}\n",
    "j = 0\n",
    "for x, y in tqdm(loader):\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    for intervention_layer in range(3):\n",
    "        for name, model in models.items():\n",
    "            model.cuda()\n",
    "            _, c = model.run_with_cache(x)\n",
    "            target_actv = c[f'hks.adapt_{intervention_layer}_0']\n",
    "            hook = partial(hook_fn, target_actv=target_actv)\n",
    "            hooks = [(f'hks.adapt_{intervention_layer}_{i}', hook) for i in range(20)]\n",
    "            with model.hooks(hooks):\n",
    "                _, cache = model.run_with_cache(x)\n",
    "            for layer in range(4):\n",
    "                for timestep in range(20):\n",
    "                    actv = cache[f'hks.adapt_{layer}_{timestep}']\n",
    "                    for map in range(32):\n",
    "                        actv_dict['Map'].append(map)\n",
    "                        actv_dict['Timestep'].append(timestep)\n",
    "                        actv_dict['Layer'].append(layer)\n",
    "                        actv_dict['Mean'].append(float(actv[:, map].mean()))\n",
    "                        actv_dict['num_active'].append(float((actv[:, map] > 1e-4).sum()))\n",
    "                        actv_dict['mean_not_null'].append(float(actv[:, map][actv[:, map] > 1e-4].mean()))   \n",
    "                        actv_dict['Norm'].append(float(actv[:, map].norm()))\n",
    "                        actv_dict['Model'].append(name)\n",
    "                        actv_dict['State'].append(float(cache[f'hks.state_{layer}_{timestep}'][:, map].mean()))\n",
    "                        actv_dict['Intervention Layer'].append(intervention_layer)\n",
    "    j += 1\n",
    "    if j > 50:\n",
    "        break\n",
    "\n",
    "actv_df = pd.DataFrame(actv_dict)\n",
    "actv_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6bb28a6b2a52186"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "actv_df['Timestep'] += 1\n",
    "actv_df['Normalized Activations'] = actv_df.groupby(['Model', 'Layer', 'Intervention Layer'], sort=False).apply(\n",
    "    lambda df: df['Mean'] / df.loc[df.Timestep == 1, 'Mean'].mean()).reset_index(level=['Model', 'Layer', 'Intervention Layer'], drop=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9babd6a554b580e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"rocket\", n_colors=4)[::-1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "263da21b8b6f93da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 3), ncols=2)\n",
    "sns.set_style('white')\n",
    "for layer in range(3):\n",
    "    sns.lineplot(data=actv_df[(actv_df.Model.isin(['Divisive Norm.'])) & (actv_df.Layer==layer + 1) & (actv_df['Intervention Layer'] == layer)], x='Timestep', y='Normalized Activations', ax=ax[0], color=palette[layer + 1])\n",
    "    sns.lineplot(data=actv_df[(actv_df.Model.isin(['Additive'])) & (actv_df.Layer==layer + 1) & (actv_df['Intervention Layer'] == layer)], x='Timestep', y='Normalized Activations', ax=ax[1], label=f'Layer {layer + 1}', color=palette[layer + 1])\n",
    "# disable gridlines\n",
    "ax[0].grid(False)\n",
    "ax[1].grid(False)\n",
    "sns.despine(offset=5)\n",
    "\n",
    "# save\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/attnl_006.svg\", format='svg')\n",
    "plt.savefig(\"figures/attnl_006.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24065b76a2521262"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
